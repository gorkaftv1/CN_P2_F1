# ğŸï¸ F1 Driver Standings - Data Lake en AWS

Pipeline completo de datos de FÃ³rmula 1 (clasificaciones de pilotos) con ingestiÃ³n en streaming y procesamiento ETL en AWS.

## ğŸ“‹ DescripciÃ³n

Sistema de Data Lake que procesa datos de clasificaciones de pilotos de F1 mediante:
- **Streaming en tiempo real**: Kinesis â†’ Firehose â†’ S3
- **Procesamiento ETL**: AWS Glue con Spark
- **Particionamiento dinÃ¡mico**: Por `raceId` y `driverId`
- **CatÃ¡logo de datos**: AWS Glue Data Catalog
- **Consultas**: Amazon Athena

## ğŸ—ï¸ Arquitectura

```
CSV Data â†’ Kinesis Stream â†’ Firehose (+ Lambda) â†’ S3 (particionado)
                                                      â†“
                                                  Glue Crawler
                                                      â†“
                                              Glue Data Catalog
                                                      â†“
                                                 Glue ETL Jobs â†’ S3 (procesado)
                                                      â†“
                                                   Athena
```

## ğŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ data/                          # Datos CSV de entrada
â”‚   â”œâ”€â”€ driver_standings.csv
â”‚   â”œâ”€â”€ drivers.csv
â”‚   â””â”€â”€ driver_standings_with_info.csv
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ simple_script.ps1         # Script de despliegue para Windows
â”‚   â”œâ”€â”€ script.sh                 # Script de despliegue para Linux/Mac
â”‚   â””â”€â”€ configure_aws.ps1         # ConfiguraciÃ³n de credenciales AWS (no subir a git)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ firehose_driver_standings.py           # Lambda para Firehose
â”‚   â”œâ”€â”€ kinesis.py                             # Productor de datos a Kinesis
â”‚   â”œâ”€â”€ merge_driver_standings.py              # PreparaciÃ³n de datos
â”‚   â”œâ”€â”€ standings_aggregation_by_race.py       # Job Glue: agregaciÃ³n por carrera
â”‚   â”œâ”€â”€ driver_standing_aggregation_by_race.py
â”‚   â””â”€â”€ driver_standing_aggregation_by_driver.py # Job Glue: agregaciÃ³n por piloto
â””â”€â”€ README.md
```

## ğŸš€ Inicio RÃ¡pido

### Prerequisitos

- **AWS CLI** configurado con credenciales
- **Python 3.12+** con entorno virtual
- **PowerShell** (Windows) o **Bash** (Linux/Mac)
- **Rol IAM** `LabRole` con permisos necesarios

### InstalaciÃ³n

1. **Clonar repositorio**
```bash
git clone <repo-url>
cd P2
```

2. **Crear entorno virtual e instalar dependencias**
```bash
python -m venv .venv
# Windows
.venv\Scripts\Activate.ps1
# Linux/Mac
source .venv/bin/activate

pip install boto3 pandas loguru
```

3. **Configurar AWS (solo primera vez)**

ObtÃ©n tus credenciales de AWS Academy y ejecuta:
```powershell
# Edita scripts/configure_aws.ps1 con tus credenciales
.\scripts\configure_aws.ps1
```

### Despliegue AutomÃ¡tico

**Windows (PowerShell):**
```powershell
cd scripts
.\simple_script.ps1
```

**Linux/Mac (Bash):**
```bash
cd scripts
./script.sh
```

El script realizarÃ¡ automÃ¡ticamente:
1. âœ… CreaciÃ³n de bucket S3 y carpetas
2. âœ… ConfiguraciÃ³n de Kinesis Stream
3. âœ… Despliegue de Lambda Function
4. âœ… ConfiguraciÃ³n de Firehose Delivery Stream
5. âœ… CreaciÃ³n de Glue Database y Crawler
6. âœ… Subida de scripts ETL a S3
7. âœ… CreaciÃ³n de Glue Jobs
8. âœ… EjecuciÃ³n del productor Kinesis
9. âœ… EjecuciÃ³n del Crawler (espera 90s + 60s)
10. âœ… EjecuciÃ³n secuencial de Jobs Glue

**DuraciÃ³n estimada:** 5-10 minutos

## ğŸ“Š Recursos Creados

### S3
- **Bucket**: `datalake-f1-driverstandings-{ACCOUNT_ID}`
- **Estructura**:
  - `raw/f1_driver_standings/` - Datos sin procesar
  - `processed/driver_standings_by_race/` - AgregaciÃ³n por carrera
  - `processed/driver_standings_by_driver/` - AgregaciÃ³n por piloto
  - `scripts/` - Scripts ETL
  - `errors/` - Errores de Firehose

### Kinesis
- **Stream**: `f1-driver-standings-stream` (1 shard)

### Lambda
- **Function**: `f1-firehose-lambda`
- **Runtime**: Python 3.10
- **PropÃ³sito**: TransformaciÃ³n y particionamiento dinÃ¡mico

### Firehose
- **Delivery Stream**: `f1-driver-standings-delivery-stream`
- **Particionamiento**: `raceId` y `driverId`
- **Buffering**: 64 MB / 60 segundos

### Glue
- **Database**: `f1_db`
- **Crawler**: `f1-driver-standings-raw-crawler`
- **Jobs**:
  - `driver-standings-by-race`
  - `driver-standings-by-driver`

## ğŸ” Consultas con Athena

Una vez completado el despliegue, puedes consultar los datos en Athena:

```sql
-- Ver datos raw
SELECT * FROM f1_db.f1_driver_standings LIMIT 10;

-- Ver datos procesados por carrera
SELECT * FROM f1_db.driver_standings_by_race LIMIT 10;

-- Ver datos procesados por piloto
SELECT * FROM f1_db.driver_standings_by_driver LIMIT 10;
```

## ğŸ› ï¸ Componentes Principales

### `kinesis.py`
Productor que lee `driver_standings_with_info.csv` y envÃ­a registros al stream de Kinesis.

### `firehose_driver_standings.py`
Lambda que procesa registros de Firehose:
- Decodifica datos en base64
- AÃ±ade claves de particiÃ³n (`raceId`, `driverId`)
- Re-encodea para S3

### `standings_aggregation_by_race.py`
Job Glue/Spark que:
- Lee datos del catÃ¡logo
- Agrega por `raceId` y `driverId`
- Calcula mÃ©tricas (puntos totales, victorias, etc.)
- Guarda en S3 formato Parquet

### `driver_standing_aggregation_by_driver.py`
Job Glue/Spark que:
- Agrega datos por piloto
- Calcula estadÃ­sticas de carrera
- Guarda resultados procesados

## âš™ï¸ ConfiguraciÃ³n

### Variables de entorno (scripts)
- `AWS_REGION`: `us-east-1`
- `ACCOUNT_ID`: Obtenido automÃ¡ticamente
- `BUCKET_NAME`: `datalake-f1-driverstandings-{ACCOUNT_ID}`
- `ROLE_ARN`: ARN del rol `LabRole`

### Glue Jobs
- **VersiÃ³n**: 4.0
- **Workers**: 2
- **Worker Type**: G.1X
- **Python Version**: 3

## ğŸ” Seguridad

- âŒ **NO subir** `configure_aws.ps1` (contiene credenciales)
- âŒ **NO subir** carpeta `.venv/`
- âŒ **NO subir** carpeta `old_scripts/`
- âœ… Usar `.gitignore` para excluir archivos sensibles
- âœ… Credenciales temporales de AWS Academy (expiran en horas)

## ğŸ“ Notas

- Las credenciales de AWS Academy son temporales y deben renovarse periÃ³dicamente
- Los Jobs de Glue se ejecutan **secuencialmente** (el segundo espera al primero)
- El Crawler espera 60 segundos para catalogar datos antes de ejecutar jobs
- Firehose espera 90 segundos para procesar y guardar datos en S3

## ğŸ› Troubleshooting

### Error: "Bucket already exists"
El script falla si los recursos ya existen. Usar `script.ps1` en `old_scripts/` para versiÃ³n con verificaciones.

### Error: "Lambda execution role"
Verificar que el rol `LabRole` tiene permisos necesarios.

### Error: "Firehose timeout"
Aumentar los tiempos de espera en el script si es necesario.

## ğŸ‘¥ Autores

- Gorka - Cloud Computing - Universidad 2025/26

## ğŸ“„ Licencia

Proyecto acadÃ©mico - Universidad 2025/26
