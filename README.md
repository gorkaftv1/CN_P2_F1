# ğŸï¸ F1 Driver Standings - Data Lake en AWS

**Proyecto**: Pipeline de Data Lake para datos de FÃ³rmula 1  
**Autor**: Gorka  
**Universidad**: Cloud Computing 2025/26  
**Fecha**: Enero 2026

Pipeline completo de datos de FÃ³rmula 1 (clasificaciones de pilotos) con ingestiÃ³n en streaming y procesamiento ETL en AWS.

## ğŸ“‹ Ãndice

1. Resumen Ejecutivo
2. Arquitectura Completa
3. Componentes AWS - ExplicaciÃ³n Detallada
4. EstimaciÃ³n de Costos
5. Optimizaciones Implementadas
6. Recomendaciones

## ğŸ“‹ DescripciÃ³n

Sistema de Data Lake que procesa datos de clasificaciones de pilotos de F1 mediante:
- **Streaming en tiempo real**: Kinesis â†’ Firehose â†’ S3
- **Procesamiento ETL**: AWS Glue con Spark
- **Particionamiento**: Por `raceId` y `driverId` (manejado por Glue)
- **CatÃ¡logo de datos**: AWS Glue Data Catalog
- **Consultas**: Amazon Athena

## ğŸ—ï¸ Arquitectura

```
CSV Data â†’ Kinesis Stream â†’ Firehose â†’ Lambda â†’ S3 raw/ (particionado por fecha)
                                                    â†“
                                               Glue Crawler
                                                    â†“
                                            Glue Data Catalog
                                                    â†“
                               Glue ETL Jobs â†’ S3 processed/ (particionado por raceId/driverId)
                                                    â†“
                                                 Athena
```

**Particionamiento**:
- **Raw Zone**: Particionado automÃ¡ticamente por fecha (`partition_date=YYYY-MM-DD`) mediante Lambda + Firehose Dynamic Partitioning
- **Processed Zone**: Particionado por `raceId` (tabla by_race) y sin particionar (tabla by_driver) mediante Glue Jobs

## ğŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ data/                          # Datos CSV de entrada
â”‚   â”œâ”€â”€ driver_standings.csv      # Datos originales de clasificaciones
â”‚   â”œâ”€â”€ drivers.csv                # InformaciÃ³n de pilotos
â”‚   â””â”€â”€ driver_standings_with_info.csv  # Dataset combinado (34,863 registros)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ timed_script.ps1           # Script principal con monitorizaciÃ³n (RECOMENDADO)
â”‚   â”œâ”€â”€ cleanup_script.ps1         # Elimina todos los recursos AWS
â”‚   â”œâ”€â”€ athena_queries.ps1         # Ejecuta consultas Athena de prueba
â”‚   â”œâ”€â”€ simple_script.ps1          # Script bÃ¡sico de despliegue
â”‚   â””â”€â”€ old_scripts/               # Versiones anteriores (no usar)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lambda/
â”‚   â”‚   â””â”€â”€ firehose_driver_standings.py       # Lambda ACTIVA: transforma datos en Firehose (elimina positionText, aÃ±ade partition_date)
â”‚   â”œâ”€â”€ producer/
â”‚   â”‚   â””â”€â”€ kinesis.py                         # Producer: envÃ­a datos a Kinesis (100 rec/batch, 2.1s delay)
â”‚   â”œâ”€â”€ glue_jobs/
â”‚   â”‚   â”œâ”€â”€ driver_standings_aggregation_by_race.py   # Glue Job: agregaciÃ³n por carrera + top driver con Window functions
â”‚   â”‚   â””â”€â”€ driver_standing_aggregation_by_driver.py  # Glue Job: agregaciÃ³n por piloto + estadÃ­sticas (sum, avg, stddev)
â”‚   â””â”€â”€ preprocessing/
â”‚       â”œâ”€â”€ merge_driver_standings.py          # Preprocessing: combina driver_standings + drivers (ejecutado previamente)
â”‚       â””â”€â”€ generate_demo.py                   # Preprocessing: genera dataset reducido (ejecutado previamente)
â””â”€â”€ README.md
```

## ğŸš€ Inicio RÃ¡pido

### Prerequisitos

- **AWS CLI** configurado con credenciales
- **Python 3.12+** con entorno virtual
- **PowerShell** (Windows) o **Bash** (Linux/Mac)
- **Rol IAM** `LabRole` con permisos necesarios

### InstalaciÃ³n

1. **Clonar repositorio**
```bash
git clone <repo-url>
cd P2
```

2. **Crear entorno virtual e instalar dependencias**
```bash
python -m venv .venv
# Windows
.venv\Scripts\Activate.ps1
# Linux/Mac
source .venv/bin/activate

pip install boto3 pandas loguru
```

3. **Configurar AWS (solo primera vez)**

ObtÃ©n tus credenciales de AWS Academy y ejecuta:
```powershell
# Edita scripts/configure_aws.ps1 con tus credenciales
.\scripts\configure_aws.ps1
```

### Despliegue AutomÃ¡tico

**Windows (PowerShell) - RECOMENDADO:**
```powershell
cd scripts
.\timed_script.ps1 -JobToRun both
```

**ParÃ¡metros disponibles:**
- `-JobToRun both` (por defecto): Ejecuta ambos jobs
- `-JobToRun race`: Solo ejecuta agregaciÃ³n por carrera
- `-JobToRun driver`: Solo ejecuta agregaciÃ³n por piloto

**Script alternativo (bÃ¡sico):**
```powershell
cd scripts
.\simple_script.ps1
```

El script `timed_script.ps1` realiza automÃ¡ticamente:
1. âœ… CreaciÃ³n de bucket S3 y carpetas
2. âœ… CreaciÃ³n de Kinesis Stream (monitorea hasta ACTIVE)
3. âœ… CreaciÃ³n de Lambda y configuraciÃ³n de Firehose con Dynamic Partitioning por fecha
4. âœ… CreaciÃ³n de Glue Database y Crawlers (2: raw + processed)
5. âœ… Subida de scripts ETL a S3
6. âœ… CreaciÃ³n de Glue Jobs (2 jobs)
7. âœ… EjecuciÃ³n del productor Kinesis (34,863 registros en batches de 100)
8. âœ… Espera monitorizada de Firehose (30s despuÃ©s de completar)
9. âœ… EjecuciÃ³n y monitoreo de Crawler RAW
10. âœ… EjecuciÃ³n y monitoreo de Glue Jobs
11. âœ… EjecuciÃ³n y monitoreo de Crawler procesado
12. âœ… Consultas Athena de prueba

**DuraciÃ³n estimada:** 8-15 minutos (depende del tamaÃ±o de datos)

## ğŸ“Š Recursos Creados

### S3
- **Bucket**: `datalake-f1-driverstandings-{ACCOUNT_ID}`
- **Estructura**:
  - `raw/f1_driver_standings/partition_date=YYYY-MM-DD/` - Datos JSONL particionados por fecha
  - `processed/driver_standings_by_race/raceId=X/` - Parquet particionado por carrera
  - `processed/driver_standings_by_driver/` - Parquet sin particiones (datos agregados)
  - `scripts/` - Scripts ETL
  - `errors/` - Errores de Firehose (si los hay)
  - `logs/` - Logs de Spark
  - `queries/` - Archivos temporales de queries

### Kinesis
- **Stream**: `f1-driver-standings-stream` (1 shard)
- **Throughput**: 1 MB/s escritura, 2 MB/s lectura

### Firehose
- **Delivery Stream**: `f1-driver-standings-delivery-stream`
- **Source**: Kinesis Stream
- **Destination**: S3 raw/ (con transformaciÃ³n Lambda)
- **Buffering**: 64 MB / 60 segundos
- **Lambda Processor**: Elimina campo `positionText`, aÃ±ade metadata `partition_date`
- **Dynamic Partitioning**: Particionado por fecha (`partition_date=YYYY-MM-DD`)

### Lambda
- **Function**: `firehose-driver-standings-lambda`
- **Runtime**: Python 3.10
- **Memory**: 128 MB
- **Timeout**: 60 segundos
- **TransformaciÃ³n**: Elimina campos redundantes y aÃ±ade fecha UTC para particionamiento

### Glue
- **Database**: `f1_db`
- **Crawlers**:
  - `f1-driver-standings-raw-crawler` â†’ Tabla: `f1_driver_standings`
  - `f1-driver-standings-processed-crawler` â†’ Tablas: `driver_standings_by_race`, `driver_standings_by_driver`
- **Jobs**:
  - `driver-standings-by-race` (Glue 4.0, 2x G.1X workers)
  - `driver-standings-by-driver` (Glue 4.0, 2x G.1X workers)

## ğŸ” Consultas con Athena

Una vez completado el despliegue, puedes consultar los datos en Athena:

```sql
-- Ver datos raw
SELECT * FROM f1_db.f1_driver_standings LIMIT 10;

-- Ver datos procesados por carrera
SELECT * FROM f1_db.driver_standings_by_race LIMIT 10;

-- Ver datos procesados por piloto
SELECT * FROM f1_db.driver_standings_by_driver LIMIT 10;
```

## ğŸ› ï¸ Componentes Principales

### `producer/kinesis.py`
Productor que lee `driver_standings_with_info.csv` (34,863 registros) y envÃ­a al stream de Kinesis.
- **Batch size**: 100 registros por llamada
- **Delay**: 1 segundo entre batches
- **DuraciÃ³n**: ~5-7 minutos para enviar todos los datos

### `lambda/firehose_driver_standings.py`
**Lambda ACTIVA** - FunciÃ³n de transformaciÃ³n en Firehose.
- **FunciÃ³n**: Elimina campo `positionText` (redundante, derivado de `position`)
- **Particionamiento**: AÃ±ade `partition_date` (fecha UTC) a metadata para Dynamic Partitioning
- **Ventaja**: Solo genera ~1-30 particiones por fecha (vs 1,100+ por raceId), evita lÃ­mite de 500
- **EjecuciÃ³n**: < 50ms por lote de 100 registros

### `glue_jobs/driver_standings_aggregation_by_race.py`
Job Glue/Spark que:
- Lee datos de `f1_db.f1_driver_standings`
- Agrega por `raceId`
- Calcula: total_drivers, total_points, top_driver (ganador), etc.
- **Escribe particionado** por `raceId` en formato Parquet

### `glue_jobs/driver_standing_aggregation_by_driver.py`
Job Glue/Spark que:
- Lee datos de `f1_db.f1_driver_standings`
- Agrega por `driverId`
- Calcula: mejor_posicion_historica, posicion_promedio, desviacion_estandar, total_carreras
- **Escribe particionado** por `driverId` en formato Parquet

## âš™ï¸ ConfiguraciÃ³n

### Variables de entorno (scripts)
- `AWS_REGION`: `us-east-1`
- `ACCOUNT_ID`: Obtenido automÃ¡ticamente
- `BUCKET_NAME`: `datalake-f1-driverstandings-{ACCOUNT_ID}`
- `ROLE_ARN`: ARN del rol `LabRole`

### Glue Jobs
- **VersiÃ³n**: 4.0
- **Workers**: 2
- **Worker Type**: G.1X
- **Python Version**: 3

## ğŸ” Seguridad

- âŒ **NO subir** `configure_aws.ps1` (contiene credenciales)
- âŒ **NO subir** carpeta `.venv/`
- âŒ **NO subir** carpeta `old_scripts/`
- âœ… Usar `.gitignore` para excluir archivos sensibles
- âœ… Credenciales temporales de AWS Academy (expiran en horas)

## ğŸ“ Notas Importantes

- **Dynamic Partitioning por fecha**: Particiona raw/ por `partition_date` (evita lÃ­mite de 500 con ~30 fechas Ãºnicas)
- **Lambda ligera**: TransformaciÃ³n simple (< 50ms), elimina 1 campo y aÃ±ade metadata de fecha
- **Particionamiento multi-nivel**: raw/ por fecha (temporal), processed/ por raceId/driverId (entidad de negocio)
- **Batch size reducido**: 100 registros para evitar saturar Firehose
- **MonitorizaciÃ³n activa**: El script espera a que cada recurso estÃ© listo antes de continuar
- **Credenciales temporales**: AWS Academy requiere renovaciÃ³n periÃ³dica
- **Jobs secuenciales**: El segundo job espera a que el primero complete
- **Cleanup completo**: `cleanup_script.ps1` elimina TODOS los recursos (usar con cuidado)

## ğŸ› Troubleshooting

### Error: "DynamicPartitioning.ActivePartitionsLimitExceeded"
**PrevenciÃ³n**: Resuelto mediante particionamiento por fecha (< 30 particiones) en lugar de raceId (> 1,100). Si aparece, verificar que Lambda estÃ© aÃ±adiendo correctamente `partition_date` a metadata.

### Error: "Bucket already exists"
**SoluciÃ³n**: Ejecutar `.\cleanup_script.ps1` primero para eliminar recursos existentes.

### Error: "Crawler still running"
**SoluciÃ³n**: El script ya incluye monitorizaciÃ³n. Si persiste, esperar manualmente a que el crawler termine.

### No hay datos en S3 raw/
**Causas posibles**:
1. Kinesis producer fallÃ³ â†’ Revisar logs en terminal
2. Firehose no estÃ¡ ACTIVE â†’ Verificar estado con AWS CLI
3. Buffering de Firehose â†’ Esperar hasta 60s para que escriba

### Jobs Glue fallan
**Causas posibles**:
1. Tabla `f1_driver_standings` no existe â†’ Ejecutar crawler raw primero
2. Permisos del rol LabRole â†’ Verificar permisos S3/Glue
3. Path incorrecto en scripts â†’ Verificar output_path en job args

### Cleanup no elimina todo
**SoluciÃ³n**: Algunos recursos pueden tardar en eliminarse (Firehose ~30s). Ejecutar cleanup dos veces si es necesario.

## ğŸ‘¥ Autores

- Gorka - Cloud Computing - Universidad 2025/26

## ğŸ“„ Licencia

Proyecto acadÃ©mico - Universidad 2025/26
